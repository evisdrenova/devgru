# devgru.yaml - Multi-Agent Consensus Configuration
# This file defines providers, workers, judges, and consensus settings

# Provider configurations
# API keys are automatically injected from environment variables:
# - OPENAI_API_KEY for OpenAI providers
# - ANTHROPIC_API_KEY for Anthropic providers
providers:
  openai:
    kind: openai
    model: gpt-4o-mini
    base_url: https://api.openai.com/v1

  openai-gpt4:
    kind: openai
    model: gpt-4o
    base_url: https://api.openai.com/v1

# Worker configurations - these are the LLMs that will answer your prompts
workers:
  - id: gpt4-mini-creative
    provider: openai
    temperature: 0.8
    max_tokens: 2048
    system_prompt: "You are a creative and thoughtful assistant."

  - id: gpt4-analytical
    provider: openai-gpt4
    temperature: 0.2
    max_tokens: 2048
    system_prompt: "You are an analytical assistant focused on accuracy and logic."

# Judge configurations - these evaluate worker responses (not yet implemented)
judges:
  - id: gpt4-judge
    provider: openai-gpt4
    system_prompt: |
      You are evaluating LLM responses for a consensus system.
      Grade each answer on a scale of 0-10 considering:
      - Accuracy of information
      - Clarity of explanation
      - Completeness of answer
      - Helpfulness to the user

      Respond ONLY with valid JSON in this format:
      {"score": <integer 0-10>, "reason": "<brief explanation>"}

# Consensus algorithm configuration
consensus:
  # Available algorithms:
  # - majority: Simple majority vote (currently just picks first successful response)
  # - score_top1: Use judges to score responses, pick highest (TODO)
  # - embedding_cluster: Group similar responses, pick largest cluster (TODO)
  # - referee: Use an LLM to pick the best response (TODO)
  algorithm: majority

  # Minimum score required for score_top1 algorithm
  min_score: 6

  # Maximum time to wait for all workers/judges
  timeout: 45s

# Cache configuration
cache:
  # Directory to store cached responses
  # Defaults to ~/.devgru/cache if not specified
  dir: ~/.devgru/cache

  # Enable/disable caching (useful for debugging)
  enabled: true

# Logging configuration
logging:
  # Log levels: debug, info, warn, error
  level: info
# Example environment variable usage:
# You can override any config value using DEVGRU_ prefixed env vars:
#
# DEVGRU_PROVIDERS_OPENAI_MODEL=gpt-4o
# DEVGRU_CONSENSUS_ALGORITHM=majority
# DEVGRU_LOGGING_LEVEL=debug
#
# The structure follows the YAML hierarchy with dots as separators.
